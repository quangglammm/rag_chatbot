# pip install chromadb sentence-transformers

import chromadb
from chromadb.utils import embedding_functions
from sentence_transformers import SentenceTransformer

# ---------------------------------------
# 1. Load Vietnamese Embedding model
# ---------------------------------------
# TODO: change target embedding model
embed_model = SentenceTransformer("VoVanPhuc/sup-SimCSE-VietNamese-phobert-base")

def embed_texts(texts):
    return embed_model.encode(texts, convert_to_numpy=True, normalize_embeddings=True)

# ---------------------------------------
# 2. Gi·∫£ s·ª≠ b·∫°n ƒë√£ c√≥ list chunks t·ª´ chunk_markdown()
#    M·ªói ph·∫ßn t·ª≠: {"doc_title": ..., "section": ..., "chunk_id": ..., "content": ...}
# ---------------------------------------
# chunks = [
#     {"doc_title": "ƒê√ÅNH GI√Å KH·∫¢ NƒÇNG CH·ªäU M·∫∂N",
#      "section": "2.1. V·∫≠t li·ªáu nghi√™n c·ª©u",
#      "chunk_id": 1,
#      "content": "Gi·ªëng l√∫a th∆°m Jasmine 85, gi·ªëng chu·∫©n kh√°ng m·∫∑n Pokkali."},
#     {"doc_title": "ƒê√ÅNH GI√Å KH·∫¢ NƒÇNG CH·ªäU M·∫∂N",
#      "section": "2.2. Ph∆∞∆°ng ph√°p nghi√™n c·ª©u",
#      "chunk_id": 2,
#      "content": "Lai h·ªØu t√≠nh gi·ªØa c√°c ngu·ªìn gen b·ªë m·∫π..."}
# ]

# ---------------------------------------
# 3. Kh·ªüi t·∫°o ChromaDB
# ---------------------------------------
client = chromadb.Client()
collection = client.create_collection(name="rice_study")

# ---------------------------------------
# 4. Th√™m chunks v√†o DB
# ---------------------------------------
def save_chunks(chunks):
    for ch in chunks:
        emb = embed_texts([ch["content"]])[0]
        collection.add(
            documents=[ch["content"]],
            embeddings=[emb],
            metadatas=[{
                "doc_title": ch["doc_title"],
                "section": ch["section"],
                "chunk_id": ch["chunk_id"]
            }],
            ids=[str(ch["chunk_id"])]
        )

    print("‚úÖ ƒê√£ l∆∞u", len(chunks), "chunks v√†o ChromaDB")

# ---------------------------------------
# 5. Truy v·∫•n th·ª≠
# ---------------------------------------
# query = "Gi·ªëng l√∫a n√†o ch·ªãu m·∫∑n t·ªët nh·∫•t?"
# q_emb = embed_texts([query])[0]

# results = collection.query(
#     query_embeddings=[q_emb],
#     n_results=2
# )

# print("\nüîé K·∫øt qu·∫£ truy v·∫•n:")
# for doc, meta in zip(results["documents"][0], results["metadatas"][0]):
#     print(f"- Section: {meta['section']} | Doc: {meta['doc_title']}")
#     print("  N·ªôi dung:", doc[:100], "...\n")
